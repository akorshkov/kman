#!/usr/bin/env python
"""Cheatsheets helper.

Displays my own cheatsheets for miscellaneous topics.
"""

import sys
import os.path
import re

import argparse
import logging

logger = logging.getLogger('kman')


_COLORS = {
    'BLACK'  : "\033[1;30m", 'D_BLACK'  : "\033[2;30m",
    'RED'    : "\033[1;31m", 'D_RED'    : "\033[2;31m",
    'GREEN'  : "\033[1;32m", 'D_GREEN'  : "\033[2;32m",
    'YELLOW' : "\033[1;33m", 'D_YELLOW' : "\033[2;33m",
    'BLUE'   : "\033[1;34m", 'D_BLUE'   : "\033[2;34m",
    'MAGENTA': "\033[1;35m", 'D_MAGENTA': "\033[2;35m",
    'CYAN'   : "\033[1;36m", 'D_CYAN'   : "\033[2;36m",
    'WHITE'  : "\033[1;37m", 'D_WHITE'  : "\033[2;37m",

    'CLRBLD' : "\033[2m",
    'CLREND' : "\033[0m",
}

# types of output stream items
_START_COLOR, _OUT_TEXT, _END_COLOR = range(3)

class _TopicFormatter():
    # Colorize strings.
    #
    # Used to color-format cheatsheet topics.

    _TOKEN_COLORS = {
        'title':   _COLORS['D_YELLOW'],
        'table':   _COLORS['D_GREEN'],
        'note':    _COLORS['GREEN'],
        'comment': _COLORS['BLUE'],
        'keyword': _COLORS['CYAN'],
        'search':  "\033[1;41;37m",  # inverted red text
    }

    # title example: = some text =
    # (start or lookbehind '|')=some text=(lookahead spaces + end or '|')
    _TOKEN_TITLE = ('title', r"(^|(?<=\|))=[^|=]+=(?=\s*($|\|))")
    # table: long srings of "====" or '|'
    _TOKEN_TABLE = ('table', r"={3,}|\|")
    # note example: > note text
    # (start or lookbehind '|')> the text(lookahead spaces + end or '|')
    _TOKEN_NOTE = ('note', r"(^|(?<=\|))>[^|]*")
    # comment example: .... <- comment here
    _TOKEN_COMMENT = ('comment', r" <- [^|]*")

    class _StringProcessor:
        # Helper for the procedure that produces colored output.
        #
        # Parses the string using given tokenizer and provides information
        # about the desired color of the current region.

        def __init__(self, tokenizer):
            # Argument:
            # - tokenizer: object that splits given string to "syntax items"
            #
            # State of the object tells: "I think that the color of original
            # string's region ending on self.cur_end_pos should be the
            # color on top of the self.colors_stack"
            self.cur_end_pos = 0
            self.colors_stack = []
            self.tokenizer = tokenizer
            self.finished = False

        def go_next(self):
            """Update the self with the information about next syntax region."""
            try:
                item_type, item_pos, body = next(self.tokenizer)
            except StopIteration:
                self.finished = True
                return

            if item_type == _START_COLOR:
                self.colors_stack.append(body)
            elif item_type == _OUT_TEXT:
                self.cur_end_pos += body  # body is the lenght of text
            else:
                assert item_type == _END_COLOR
                self.colors_stack.pop()

        @staticmethod
        def select_processor(processors):
            """Selects not-finished processor with smallest cur_end_pos."""
            chosen_processor = None
            for p in processors:
                if chosen_processor is None:
                    if not p.finished:
                        chosen_processor = p
                elif p.cur_end_pos < chosen_processor.cur_end_pos:
                    assert not p.finished
                    chosen_processor = p

            return chosen_processor

        @staticmethod
        def get_cur_color(processors):
            """sorted by priority processrs -> real color of output text.

            Different processors might have different opinions on what color
            should be used now!
            """
            for processor in processors:
                if processor.colors_stack:
                    return processor.colors_stack[-1]
            return _COLORS['CLREND']

    class _DummyTokenizer:
        # mimics compiled re pattern, but never founds anything
        @classmethod
        def finditer(cls, _string):

            return cls._dummy_generator()

        @staticmethod
        def _dummy_generator():
            return
            yield

    def __init__(self, _topic_header_lines):
        """Constructor of _TopicFormatter.

        Arguments:
        - _topic_header_lines: list of strings which contain formatter
            configuration directives. Processing of these directives is
            not implemented yet.
        """
        keywords = ['git', 'ps', 'apt', 'yum']  # so far hardcoded
        search_patterns = []
        top_tokens = [
            self._TOKEN_TITLE,
            self._TOKEN_TABLE,
            self._TOKEN_NOTE,
            self._TOKEN_COMMENT,
        ]
        if keywords:
            token_keyword = (
                'keyword',
                "|".join(
                    # (start or lookbehind space or '|')text(-optional-suffix)(end or lookahead space)
                    r"(^|(?<=\s)|(?<=\|)){}(-[-a-zA-Z]*)?($|(?=\s))".format(kw)
                    for kw in keywords)
            )
            top_tokens.append(token_keyword)
            self._kw_tokenizer = self._make_tokenizer([token_keyword, ])
        else:
            token_keyword = None
            self._kw_tokenizer = self._DummyTokenizer()

        if search_patterns:
            token_search = (
                'search',
                "|".join(s_pattern for s_pattern in search_patterns)
            )
            self._search_tokenizer = self._make_tokenizer([token_search, ])
        else:
            self._search_tokenizer = self._DummyTokenizer()

        self._tokenizer = self._make_tokenizer(top_tokens)

    def format_topic_line(self, topic_line):
        """Returns colorized string"""
        return "".join(part for part in self._generate_string_parts(topic_line))

    def _generate_string_parts(self, topic_line):
        """Generates text chunks and color sequences ready for output"""
        line_len = len(topic_line)
        cur_pos = 0
        cur_out_color = _COLORS['CLREND']

        processors = [
            self._StringProcessor(self._string_to_syntax_items(0, topic_line, self._search_tokenizer)),
            self._StringProcessor(self._string_to_syntax_items(0, topic_line, self._tokenizer)),
        ]

        while cur_pos < line_len:
            processor = self._StringProcessor.select_processor(processors)

            if cur_pos < processor.cur_end_pos:
                next_color = self._StringProcessor.get_cur_color(processors)
                if cur_out_color != next_color:
                    if cur_out_color != _COLORS['CLREND']:
                        # to fully reset boldness/brightness it's necessary to terminal
                        yield _COLORS['CLREND']
                    cur_out_color = next_color
                    yield cur_out_color
                yield topic_line[cur_pos:processor.cur_end_pos]
                cur_pos = processor.cur_end_pos
            else:
                processor.go_next()

        yield _COLORS['CLREND']

    def _string_to_syntax_items(self, orig_start_pos, string, tokenizer):
        # generates "syntax items" from string.
        #
        # Possible syntax items:
        # (_START_COLOR, None,      color_sequence)
        # (_OYT_TEXT,    start_pos, lenght)
        # (_END_COLOR,   None,      None)
        #
        # Arguments:
        # - orig_start_pos: prosition of the string to parse in the original
        #                   string. Not zero if nested syntax rules are used.
        # - string: the string to parse
        # - tokenizer: compiled re pattern
        pos = 0
        for match in tokenizer.finditer(string):
            m_start, m_end = match.span()
            if pos < m_start:
                yield (_OUT_TEXT, orig_start_pos+pos, m_start-pos)

            for part in self._syntax_region_to_syntax_items(orig_start_pos+m_start, match):
                yield part

            pos = m_end

        if pos < len(string):
            yield (_OUT_TEXT, orig_start_pos+pos, len(string)-pos)

    def _syntax_region_to_syntax_items(self, orig_start_pos, match):
        # match -> syntax items
        #
        # match means that some syntax region is found in string. Note
        # that different parts of match may require different coloring.
        m_start, m_end = match.span()
        if match.lastgroup == 'title':
            yield (_OUT_TEXT, orig_start_pos+m_start, 1)  # starting '='
            yield (_START_COLOR, None, self._TOKEN_COLORS['title'])
            yield (_OUT_TEXT, orig_start_pos+m_start+1, m_end-m_start-2)  # the text
            yield (_END_COLOR, None, None)
            yield (_OUT_TEXT, orig_start_pos+m_end-1, 1)  # trailing '='
        elif match.lastgroup == 'comment':
            yield (_START_COLOR, None, self._TOKEN_COLORS['comment'])
            nested_parts = self._string_to_syntax_items(
                orig_start_pos+m_start, match.string[m_start:m_end], self._kw_tokenizer)
            for part in nested_parts:
                yield part
            yield (_END_COLOR, None, None)
        else:
            yield (_START_COLOR, None, self._TOKEN_COLORS[match.lastgroup])
            yield (_OUT_TEXT, orig_start_pos+m_start, m_end-m_start)
            yield (_END_COLOR, None, None)

    @staticmethod
    def _make_tokenizer(tokens):
        # [(region_name, re_pattern), ] -> compiled re pattern
        return re.compile(
            "|".join("(?P<{}>{})".format(name, pattern) for name, pattern in tokens))


def do_print_topic(topic_name):
    """Find ad print topic."""
    topic_file_path, examined_dirs = _find_topic_file(topic_name)

    if topic_file_path is None:
        logger.error("Topic '%s' not found. Examined directories: %s",
                     topic_name, examined_dirs)
        sys.exit(1)

    formatter = None
    reading_topic_meta = True
    topic_header_lines = []
    for line in open(topic_file_path):
        line = line.rstrip()
        if reading_topic_meta:
            # still reading the "header" part of the topic
            # which contains some meta information
            if line.startswith('--'):
                topic_header_lines.append(line)
                continue
            else:
                formatter = _TopicFormatter(topic_header_lines)
                reading_topic_meta = False

        print(formatter.format_topic_line(line))


def _find_topic_file(topic_name):
    # find file by topic name
    topic_filename = topic_name + ".topic"
    examined_dirs = []
    for dir_name in ["~/.kman/topics", ]:
        dir_name = os.path.normpath(os.path.expanduser(dir_name))
        examined_dirs.append(dir_name)
        topic_file_path = os.path.join(dir_name, topic_filename)
        if os.path.exists(topic_file_path):
            return topic_file_path, examined_dirs

    return None, examined_dirs


def main():
    """kman - print cheatsheet topic or list of topics."""
    # parse cmdline arguments
    parser = argparse.ArgumentParser(
        description="Display cheatsheets for miscelaneous topics",
        epilog=("If the topic is not specified prints the list of "
                "available topics")
    )

    parser.add_argument("-v", "--verbose", action='store_true',
                        help="print some debug data")

    parser.add_argument("topic", nargs='?',
                        help="the topic to display cheatsheet about")

    args = parser.parse_args()

    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.WARNING)

    # and do the job
    if args.topic is None:
        assert False, "Not implemented."
    else:
        do_print_topic(args.topic)


if __name__ == '__main__':
    main()
