#!/usr/bin/env python
"""Cheatsheets helper.

Displays my own cheatsheets for miscellaneous topics.
"""

import sys
import os
import os.path
import re

import argparse
import logging


_COLORS = {
    'BLACK'  : "\033[1;30m", 'D_BLACK'  : "\033[2;30m",
    'RED'    : "\033[1;31m", 'D_RED'    : "\033[2;31m",
    'GREEN'  : "\033[1;32m", 'D_GREEN'  : "\033[2;32m",
    'YELLOW' : "\033[1;33m", 'D_YELLOW' : "\033[2;33m",
    'BLUE'   : "\033[1;34m", 'D_BLUE'   : "\033[2;34m",
    'MAGENTA': "\033[1;35m", 'D_MAGENTA': "\033[2;35m",
    'CYAN'   : "\033[1;36m", 'D_CYAN'   : "\033[2;36m",
    'WHITE'  : "\033[1;37m", 'D_WHITE'  : "\033[2;37m",

    'CLRBLD' : "\033[2m",
    'CLREND' : "\033[0m",
}

# types of output stream items
_START_COLOR, _OUT_TEXT, _END_COLOR = range(3)


class _TopicFormatter:
    # Colorize strings.
    #
    # Used to color-format cheatsheet topics.

    _TOKEN_COLORS = {
        'title':   _COLORS['D_YELLOW'],
        'table':   _COLORS['D_GREEN'],
        'note':    _COLORS['GREEN'],
        'comment': _COLORS['BLUE'],
        'keyword': _COLORS['CYAN'],
        'search':  "\033[1;41;37m",  # inverted red text
    }

    # title example: = some text =
    # (start or lookbehind '|')=some text=(lookahead spaces + end or '|')
    _TOKEN_TITLE = ('title', r"(^|(?<=\|))=[^|=]+=(?=\s*($|\|))")
    # table: long srings of "====" or "----" or '|'
    _TOKEN_TABLE = ('table', r"={3,}|-{3,}|\|")
    # note example: > note text
    # (start or lookbehind '|')> the text(lookahead spaces + end or '|')
    _TOKEN_NOTE = ('note', r"(^|(?<=\|))>[^|]*")
    # comment example: .... <- comment here
    _TOKEN_COMMENT = ('comment', r" <- [^|]*")

    # command-line token
    # (start or lookbehind '|')$ the command (lookahead spaces + end or '|')
    _TOKEN_CMDLINE = ('cmd_line', r"(^|(?<=\|))(\$|#) [^|]*(?=\s*($|\|))")

    class _StringProcessor:
        # Helper for the procedure that produces colored output.
        #
        # Parses the string using given tokenizer and provides information
        # about the desired color of the current region.

        def __init__(self, tokenizer):
            # Argument:
            # - tokenizer: object that splits given string to "syntax items"
            #
            # State of the object tells: "I think that the color of original
            # string's region ending on self.cur_end_pos should be the
            # color on top of the self.colors_stack"
            self.cur_end_pos = 0
            self.colors_stack = []
            self.tokenizer = tokenizer
            self.finished = False

        def go_next(self):
            """Update the self with the information about next syntax region."""
            try:
                item_type, item_pos, body = next(self.tokenizer)
            except StopIteration:
                self.finished = True
                return

            if item_type == _START_COLOR:
                self.colors_stack.append(body)
            elif item_type == _OUT_TEXT:
                self.cur_end_pos += body  # body is the lenght of text
            else:
                assert item_type == _END_COLOR
                self.colors_stack.pop()

        @staticmethod
        def select_processor(processors):
            """Selects not-finished processor with smallest cur_end_pos."""
            chosen_processor = None
            for p in processors:
                if chosen_processor is None:
                    if not p.finished:
                        chosen_processor = p
                elif p.cur_end_pos < chosen_processor.cur_end_pos:
                    assert not p.finished
                    chosen_processor = p

            return chosen_processor

        @staticmethod
        def get_cur_color(processors):
            """sorted by priority processrs -> real color of output text.

            Different processors might have different opinions on what color
            should be used now!
            """
            for processor in processors:
                if processor.colors_stack:
                    return processor.colors_stack[-1]
            return _COLORS['CLREND']

    class _DummyTokenizer:
        # mimics compiled re pattern, but never founds anything
        @classmethod
        def finditer(cls, _string):

            return cls._dummy_generator()

        @staticmethod
        def _dummy_generator():
            return
            yield

    def __init__(self, keywords, search_pattern):
        """Constructor of _TopicFormatter.

        Arguments:
        - keywords: collection of keywords
        - search_pattern: re pattern to search in topic
        Both are used for color formatting.
        """
        top_tokens = [
            self._TOKEN_TITLE,
            self._TOKEN_TABLE,
            self._TOKEN_NOTE,
            self._TOKEN_COMMENT,
            self._TOKEN_CMDLINE,
        ]
        cmd_line_tokens = [  # nested syntax rules for command-line
            self._TOKEN_COMMENT,
        ]

        if keywords:
            token_keyword = (
                'keyword',
                "|".join(
                    # (start or lookbehind space or '|')text(-optional-suffix)(end or lookahead space)
                    r"(^|(?<=\s)|(?<=\|)){}(-[-a-zA-Z]*)?($|(?=\s))".format(kw)
                    for kw in keywords)
            )
            top_tokens.append(token_keyword)
            cmd_line_tokens.append(token_keyword)
            self._kw_tokenizer = self._make_tokenizer([token_keyword, ])
        else:
            token_keyword = None
            self._kw_tokenizer = self._DummyTokenizer()

        if search_pattern:
            token_search = ('search', search_pattern)
            self._search_tokenizer = self._make_tokenizer([token_search, ])
        else:
            self._search_tokenizer = self._DummyTokenizer()

        self._tokenizer = self._make_tokenizer(top_tokens)
        self._cmd_line_tokenizer = self._make_tokenizer(cmd_line_tokens)

    def format_topic_line(self, topic_line):
        """Returns colorized string"""
        return "".join(part for part in self._generate_string_parts(topic_line))

    def _generate_string_parts(self, topic_line):
        """Generates text chunks and color sequences ready for output"""
        line_len = len(topic_line)
        cur_pos = 0
        cur_out_color = _COLORS['CLREND']

        processors = [
            self._StringProcessor(self._string_to_syntax_items(0, topic_line, self._search_tokenizer)),
            self._StringProcessor(self._string_to_syntax_items(0, topic_line, self._tokenizer)),
        ]

        while cur_pos < line_len:
            processor = self._StringProcessor.select_processor(processors)

            if cur_pos < processor.cur_end_pos:
                next_color = self._StringProcessor.get_cur_color(processors)
                if cur_out_color != next_color:
                    if cur_out_color != _COLORS['CLREND']:
                        # to fully reset boldness/brightness it's necessary to terminal
                        yield _COLORS['CLREND']
                    cur_out_color = next_color
                    yield cur_out_color
                yield topic_line[cur_pos:processor.cur_end_pos]
                cur_pos = processor.cur_end_pos
            else:
                processor.go_next()

        yield _COLORS['CLREND']

    def _string_to_syntax_items(self, orig_start_pos, string, tokenizer):
        # generates "syntax items" from string.
        #
        # Possible syntax items:
        # (_START_COLOR, None,      color_sequence)
        # (_OUT_TEXT,    start_pos, lenght)
        # (_END_COLOR,   None,      None)
        #
        # Arguments:
        # - orig_start_pos: prosition of the string to parse in the original
        #                   string. Not zero if nested syntax rules are used.
        # - string: the string to parse
        # - tokenizer: compiled re pattern
        pos = 0
        for match in tokenizer.finditer(string):
            m_start, m_end = match.span()
            if pos < m_start:
                yield (_OUT_TEXT, orig_start_pos+pos, m_start-pos)

            for part in self._syntax_region_to_syntax_items(orig_start_pos+m_start, match):
                yield part

            pos = m_end

        if pos < len(string):
            yield (_OUT_TEXT, orig_start_pos+pos, len(string)-pos)

    def _syntax_region_to_syntax_items(self, orig_start_pos, match):
        # match -> syntax items
        #
        # match means that some syntax region is found in string. Note
        # that different parts of match may require different coloring.
        m_start, m_end = match.span()
        if match.lastgroup == 'title':
            yield (_OUT_TEXT, orig_start_pos+m_start, 1)  # starting '='
            yield (_START_COLOR, None, self._TOKEN_COLORS['title'])
            yield (_OUT_TEXT, orig_start_pos+m_start+1, m_end-m_start-2)  # the text
            yield (_END_COLOR, None, None)
            yield (_OUT_TEXT, orig_start_pos+m_end-1, 1)  # trailing '='
        elif match.lastgroup == 'comment':
            yield (_START_COLOR, None, self._TOKEN_COLORS['comment'])
            nested_parts = self._string_to_syntax_items(
                orig_start_pos+m_start, match.string[m_start:m_end], self._kw_tokenizer)
            for part in nested_parts:
                yield part
            yield (_END_COLOR, None, None)
        elif match.lastgroup == 'cmd_line':
            yield (_START_COLOR, None,
                   _COLORS['D_GREEN'] if match.string[m_start] == '$' else _COLORS['RED'])
            yield (_OUT_TEXT, orig_start_pos+m_start, 2) # prompt + space
            yield (_END_COLOR, None, None)
            yield (_START_COLOR, None, _COLORS['WHITE'])
            nested_parts = self._string_to_syntax_items(
                orig_start_pos+m_start+2, match.string[m_start+2:m_end], self._cmd_line_tokenizer)
            for part in nested_parts:
                yield part
            yield (_END_COLOR, None, None)
        else:
            yield (_START_COLOR, None, self._TOKEN_COLORS[match.lastgroup])
            yield (_OUT_TEXT, orig_start_pos+m_start, m_end-m_start)
            yield (_END_COLOR, None, None)

    @staticmethod
    def _make_tokenizer(tokens):
        # [(region_name, re_pattern), ] -> compiled re pattern
        return re.compile(
            "|".join("(?P<{}>{})".format(name, pattern) for name, pattern in tokens))


class _TopicReader:
    # helper file-like object, which yields topic file lines.
    #
    # Purpose of this class is to detect end of topic meta and yield
    # a None marker between meta lines and rest of the topic.
    def __init__(self, filename):
        self.filename = filename
        self.fobj = None
        self.the_generator = None

    def __enter__(self):
        assert not self.fobj  # entered previously - must be an error
        self.fobj = open(self.filename)
        return self

    def __exit__(self, *_):
        self.fobj.close()

    def __iter__(self):
        if self.the_generator is None:
            assert self.fobj, "_TopicReader should be used as context manager"
            self.the_generator = self._prepare_the_generator(self.fobj)
        return self.the_generator

    @staticmethod
    def _prepare_the_generator(file_obj):
        # yileds the result values (lines from the file and separator)

        reading_header = True
        for line in file_obj:
            if reading_header:
                if line.startswith('--'):
                    yield line
                else:
                    reading_header = False
                    yield None
                    yield line
            else:
                yield line


class _TopicMeta:
    # topic metadata.
    #
    # Topic file contains some metadata in the first several lines starting
    # with '--'.

    # header markers
    _HEADER_TITLE    = "-- title:"
    _HEADER_DESCR    = "-- descr:"
    _HEADER_ITEMS    = "-- items:"
    _HEADER_KEYWORDS = "-- keywords:"

    # static structure of the colored description of metadata
    _COLORED_DESCR_PARTS = [
        _TopicFormatter._TOKEN_COLORS['keyword'],
        # title goes here
        (_COLORS['CLREND'] +
         _TopicFormatter._TOKEN_COLORS['table'] + '| ' + _COLORS['CLREND'] +
         _TopicFormatter._TOKEN_COLORS['note']),
        # description goes here
        _COLORS['CLREND'] + ' (',
        # path goes here
        ')'
    ]

    def __init__(self, filename, topic_reader):
        # consume metadata lines from topic_reader, parse them
        self.filename = filename
        self.title = None
        self.descr = None
        self.titems = set()
        self.keywords = set()

        for header_line in topic_reader:
            if header_line is None:
                # finished reading topic meta data
                break

            if header_line.startswith(self._HEADER_TITLE):
                self.title = header_line[len(self._HEADER_TITLE):].strip()
            elif header_line.startswith(self._HEADER_DESCR):
                self.descr = header_line[len(self._HEADER_DESCR):].strip()
            elif header_line.startswith(self._HEADER_ITEMS):
                items_text = header_line[len(self._HEADER_ITEMS):]
                self.titems.update(items_text.split())
            elif header_line.startswith(self._HEADER_KEYWORDS):
                keywords_text = header_line[len(self._HEADER_KEYWORDS):]
                self.keywords.update(keywords_text.split())

    def make_colored_descr(self):
        """topic meta -> colorized description of the topic."""
        title = self.title or "unknown"
        title = "{: <12}".format(title)

        descr = self.descr or "- no description -"

        return "".join(p for p in [
            self._COLORED_DESCR_PARTS[0],
            title,
            self._COLORED_DESCR_PARTS[1],
            descr,
            self._COLORED_DESCR_PARTS[2],
            self.filename,
            self._COLORED_DESCR_PARTS[3]
        ])


def do_print_topic(topic_file_path, search_words, search_texts):
    """print the topic."""

    search_pattern = _make_search_pattern(search_words, search_texts)

    formatter = None
    reading_topic_meta = True
    topic_header_lines = []
    with _TopicReader(topic_file_path) as f:
        topic_meta = _TopicMeta(topic_file_path, f)
        formatter = _TopicFormatter(topic_meta.keywords, search_pattern)

        for line in f:
            print(formatter.format_topic_line(line.rstrip()))


def _make_search_pattern(whole_words, text_parts):
    # search words -> re pattern
    whole_words_pattern = "|".join(
        r"\b{}\b".format(x)
        for x in whole_words)
    text_pattern = "|".join(
        r"{}".format(x)
        for x in text_parts)
    if whole_words_pattern and text_pattern:
        return whole_words_pattern + "|" + text_pattern
    elif whole_words_pattern:
        return whole_words_pattern
    else:
        return text_pattern


def find_topic_by_name(topics_dirs, topic_name):
    # find topic by name
    #
    # Returns wither topic file path or None

    topic_filename = (
        topic_name if topic_name.endswith(".topic") else topic_name + ".topic")

    for dir_name in topics_dirs:
        dir_name = os.path.normpath(os.path.expanduser(dir_name))
        topic_file_path = os.path.join(dir_name, topic_filename)
        if os.path.exists(topic_file_path):
            return topic_file_path

    return None


def find_topic_by_topicitem(topics_dirs, topic_item):
    # find topic file by title or one of the topic items (both
    # defined in topic's metadata).
    #
    # Returns list of meta's of found topics.

    matching_all = []        # either by title or by topic items
    matching_by_title = []   # only by title
    for topic_file in find_all_topic_files(topics_dirs):
        with _TopicReader(topic_file) as f:
            topic_meta = _TopicMeta(topic_file, f)

            if topic_meta.title == topic_item:
                matching_by_title.append(topic_meta)

            if topic_item in topic_meta.titems:
                matching_all.append(topic_meta)

    if len(matching_by_title) == 1:
        return matching_by_title

    return matching_all


def search_topics_by_pattern(topics_dirs, whole_words, text_parts):
    """Find topics contaning specified words/text.

    Returns list of meta's of the matching topics.
    """

    search_pattern = _make_search_pattern(whole_words, text_parts)
    search_pattern = re.compile(search_pattern)

    matching_topics_metas = []
    for topic_file in find_all_topic_files(topics_dirs):
        with _TopicReader(topic_file) as f:
            topic_meta = _TopicMeta(topic_file, f)

            # now reading the topic body lines
            for line in f:
                if search_pattern.search(line) is not None:
                    matching_topics_metas.append(topic_meta)
                    break

    return matching_topics_metas


def get_all_topic_metas(topics_dirs):
    """yields metas of all available topics."""
    for topic_file in find_all_topic_files(topics_dirs):
        with _TopicReader(topic_file) as f:
            yield _TopicMeta(topic_file, f)


def find_all_topic_files(topics_dirs):
    """Iterate through all the available topics"""
    for dir_name in topics_dirs:
        for sub_dir, _x, filenames in os.walk(dir_name):
            for fname in sorted(filenames):
                if fname.endswith(".topic"):
                    yield os.path.join(dir_name, sub_dir, fname)


def main():
    """kman - print cheatsheet topic or list of topics."""
    # parse cmdline arguments
    parser = argparse.ArgumentParser(
        description="Display cheatsheets for miscelaneous topics",
        epilog=("If the topic is not specified prints the list of "
                "available topics")
    )

    parser.add_argument("-v", "--verbose", action='store_true',
                        help="print some debug data")

    parser.add_argument("-s", "--search", nargs="+", default=[],
                        help="search the text in all topics (or in the specified topic)")

    parser.add_argument("-S", "--search-word", nargs="+", default=[],
                        help="search the word in all topics (or in the specified topic)")

    parser.add_argument("topic", nargs='?',
                        help="the topic to display. Topic is selected 1) by filename, "
                        "2) or by title, 3) or by topic's metadata item")

    args = parser.parse_args()

    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.WARNING)

    topics_dirs = [
        os.path.expanduser("~/.kman/topics"),
    ]

    # and do the job
    if args.topic is None:
        if args.search_word or args.search:
            matching_topics = search_topics_by_pattern(
                topics_dirs, args.search_word, args.search)
            if not matching_topics:
                print("No topics contain the searth pattern")
                return 0
            print("Search pattern found in the following {} topic(s):".format(len(matching_topics)))
            for topic_meta in matching_topics:
                print(topic_meta.make_colored_descr())
            if len(matching_topics) == 1:
                print("")
                do_print_topic(matching_topics[0].filename, args.search_word, args.search)
            return 0
        else:
            # print list of all the topics
            num_topics = 0
            for topic_meta in get_all_topic_metas(topics_dirs):
                print(topic_meta.make_colored_descr())
                num_topics += 1
            print("---\n Total: {} tipic(s) found".format(num_topics))
            return 0
    else:
        # the topic name is specified. Find it and print it.
        topic_file_path = find_topic_by_name(topics_dirs, args.topic)
        if topic_file_path:
            # topic was found by name
            do_print_topic(topic_file_path, args.search_word, args.search)
            return 0
        elif not args.topic.endswith(".topic"):
            # try to search for topic by topics metadata
            matching_topics = find_topic_by_topicitem(topics_dirs, args.topic)
            if matching_topics:
                for topic_meta in matching_topics:
                    print(topic_meta.make_colored_descr())

                if len(matching_topics) == 1:
                    print("")
                    do_print_topic(matching_topics[0].filename, args.search_word, args.search)
                    return 0
                else:
                    print("---\n Total: {} tipic(s) found".format(matching_topics))
                    return 1
        print("Topic '{}' not found. Examined directories: {}".format(
            args.topic, topics_dirs))
        return 1


if __name__ == '__main__':
    sys.exit(main())
